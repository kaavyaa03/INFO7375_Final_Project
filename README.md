# INFO7375_Final_Project
by Kaavya Loganathan (002317475)
# PaperPulse RAG  
Prompt Engineering + Retrieval-Augmented Generation System

## Project Overview
PaperPulse RAG is a generative AI system that answers user questions and generates summaries by grounding responses strictly in retrieved documents. The project demonstrates the practical implementation of **Prompt Engineering** and **Retrieval-Augmented Generation (RAG)** to reduce hallucinations and improve factual reliability.

The system retrieves relevant document chunks from a vector database and constructs responses using structured prompts that enforce citation and context constraints.

---

## Core Components Implemented

### 1. Prompt Engineering
- Designed structured prompts for:
  - Question Answering
  - Document Summarization
- Enforced context-restricted generation (answers are based only on retrieved content)
- Included explicit citation requirements in outputs
- Implemented safe fallback responses when insufficient evidence is available
- Managed user interaction modes (Ask / Summarize)

### 2. Retrieval-Augmented Generation (RAG)
- Built a local knowledge base from text documents
- Implemented document chunking with overlap to preserve context
- Generated embeddings for chunks
- Stored and retrieved embeddings using a FAISS vector database
- Applied top-k retrieval with similarity threshold filtering

---

## System Architecture
1. User interacts with a Streamlit web interface
2. Requests are sent to a FastAPI backend
3. Documents are ingested, chunked, embedded, and stored in FAISS
4. User queries trigger retrieval of relevant chunks
5. Prompt-engineered responses are generated using retrieved context
6. Outputs include:
   - Answer
   - Citations
   - Retrieval metrics

---

## Tech Stack
- Python
- FastAPI (backend API)
- Streamlit (interactive UI)
- FAISS (vector database)
- SentenceTransformers (text embeddings)

---

## How to Run the Project

### 1. Install Dependencies
pip install -r requirements.txt

### 2. Start the FastAPI Backend
python -m uvicorn app.api:app --reload --port 8000

### 3. Run the Streamlit Interface
streamlit run app/ui_streamlit.py

### 4. Build the Knowledge Base

Use the Build Knowledge Base button in the Streamlit UI
or call the /ingest API endpoint.

### 5. Query the System

Ask factual questions using Ask mode

Generate structured summaries using Summarize mode

View citations and retrieval metrics with each response

Example Outputs

Sample outputs generated by the system are saved in:

examples/example_outputs/
  output1.json
  output2.json


These files demonstrate:

Grounded answers

Source citations

Retrieval metrics

Ethical Considerations

The system uses only user-provided documents

No personal or external data is collected

Explicit citations help reduce hallucinations

The system clearly reports limitations when evidence is insufficient

Users are responsible for ensuring uploaded documents comply with copyright and privacy regulations

Future Improvements

Integrate a large language model for richer generation while preserving grounding

Add advanced reranking for improved retrieval accuracy

Support additional document formats (PDF, HTML)

Expand evaluation metrics for retrieval quality
